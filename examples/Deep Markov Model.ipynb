{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.poutine as poutine\n",
    "from pyro.infer import SVI, Trace_ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Emitter(nn.Module):\n",
    "    def __init__(self, input_dim, z_dim, emission_dim):\n",
    "        super(Emitter, self).__init__()\n",
    "        self.lin_z_to_hidden = nn.Linear(z_dim, emission_dim)\n",
    "        self.lin_hidden_to_hidden = nn.Linear(emission_dim, emission_dim)\n",
    "        self.lin_hidden_to_input = nn.Linear(emission_dim, input_dim)\n",
    "        \n",
    "    def __call__(self, z_t):\n",
    "        h1 = F.relu(self.lin_z_to_hidden(z_t))\n",
    "        h2 = F.relu(self.lin_hidden_to_hidden(h1))\n",
    "        ps = F.sigmoid(self.lin_hidden_to_input(h2))\n",
    "        return ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedTransition(nn.Module):\n",
    "    def __init__(self, z_dim, transition_dim):\n",
    "        super(GatedTransition, self).__init__()\n",
    "        self.lin_gate_z_to_hidden = nn.Linear(z_dim, transition_dim)\n",
    "        self.lin_gate_hidden_to_z = nn.Linear(transition_dim, z_dim)\n",
    "        self.lin_proposed_mean_z_to_hidden = nn.Linear(z_dim, transition_dim)\n",
    "        self.lin_proposed_mean_hidden_to_z = nn.Linear(transition_dim, z_dim)\n",
    "        self.lin_sig = nn.Linear(z_dim, z_dim)\n",
    "        self.lin_z_to_loc = nn.Linear(z_dim, z_dim)\n",
    "        self.lin_z_to_loc.weight.data = torch.eye(z_dim)\n",
    "        self.lin_z_to_loc.bias.data = torch.zeros(z_dim)\n",
    "        \n",
    "    def forward(self, z_t_1):\n",
    "        _gate = F.relu(self.lin_gate_z_to_hidden(z_t_1))\n",
    "        gate = F.sigmoid(self.lin_gate_hidden_to_z(_gate))\n",
    "        _proposed_mean = F.relu(self.lin_proposed_mean_z_to_hidden(z_t_1))\n",
    "        proposed_mean = self.lin_proposed_mean_hidden_to_z(_proposed_mean)\n",
    "        loc = (1 - gate) * self.lin_z_to_loc(z_t_1) + gate * proposed_mean\n",
    "        scale = F.softplus(self.lin_sig(F.relu(proposed_mean)))\n",
    "        return loc, scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepMarkov(nn.Module):\n",
    "    def model(self, mini_batch, mini_batch_reversed, mini_batch_mask,\n",
    "              mini_batch_seq_lengths, annealing_factor=1.0):\n",
    "        T_max = mini_batch.size(1)\n",
    "        # Register all of PyTorch submodules\n",
    "        pyro.module('dmm', self)\n",
    "        \n",
    "        z_prev = self.z_0.expand(mini_batch.size(0), self.z_0.size(0))\n",
    "        \n",
    "        with pyro.iarange('z_minibatch', len(mini_batch)):\n",
    "            for t in range(1, T_max + 1):\n",
    "                z_loc, z_scale = self.trans(z_prev)\n",
    "                z_t = pyro.sample(\"z_%d\" % t, dist.Normal(z_loc, z_scale))\n",
    "                emission_probs_t = self.emitter(z_t)\n",
    "                pyro.sample('obs_x_%d' % t,\n",
    "                            dist.Bernoulli(emission_probs_t),\n",
    "                            obs=mini_batch[:, t-1, :])\n",
    "                with poutine.scale(None, annealing_factor):\n",
    "                    z_t = pyro.sample('z_%d' % t,\n",
    "                                      dist.Normal(z_loc, z_scale)\n",
    "                                      .mask(mini_batch_mask[:, t-1:t])\n",
    "                                      .independent(1))\n",
    "                \n",
    "                emission_probs_t = self.emitter(z_t)\n",
    "            \n",
    "                pyro.sample(\"obs_x_%d\" % t,\n",
    "                            dist.Bernoulli(emission_probs_t)\n",
    "                                .mask(mini_batch_mask[:, t - 1:t])\n",
    "                                .independent(1),\n",
    "                            obs=mini_batch[:, t - 1, :])\n",
    "            \n",
    "                z_prev = z_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$y = x + sin(\\alpha(x + w)) + sin(\\beta(x + w)) + w$ with $w \\sim N(0, 0.032), \\alpha = 4, \\beta = 13$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
